// filename: cw3_student.uclcg
// tabGroup: Coursework
// thumbnail: cw3_thumb.png
// displayname: Coursework 3 - 2023/2024
// shortDescription: Coursework 3 - Path Tracing
// author: None
// isHidden: false

function setup()
{
	UI = {};
	UI.tabs = [];
	UI.titleLong = 'Path Tracer';
	UI.titleShort = 'PathTracer';
	UI.numFrames = 1000;
	UI.maxFPS = 1000;
	UI.renderWidth = 1024;
	UI.renderHeight = 512;

	UI.tabs.push(
		{
		visible: true,
		type: `x-shader/x-fragment`,
		title: `Raytracing`,
		id: `TraceFS`,
		initialValue: `#define SOLUTION_LIGHT
#define SOLUTION_BOUNCE
#define SOLUTION_THROUGHPUT
#define SOLUTION_AA
//#define SOLUTION_MB
#define SOLUTION_VR
// Please locate SOLUTION_VR def, there are three boolean variance to switch different variance reduction methods.

// Uncomment this to activate UNIT_TEST, this test only evaluate whether getRandomDirection samples points on a sphere.
// Check "https://github.com/Kim-Xerxes/COMP0027-Computer-Graphics/blob/main/CW3.ipynb" to test whether getRandomDirection is well-distributed on a sphere.
// The upward link also includes explanation about variance reduction techniques
//#define UNIT_TEST


precision highp float;

#define M_PI 3.14159265359

struct Material {
	#ifdef SOLUTION_LIGHT
	// In the tone mapping part, gamma value is used to correct the final pixel by a nonlinear operation below.
	// corrected_value = original_value ^ (1.0 / gamma)
	// The gamma value here can affect the overall brightness and contrast of the image, which can make the image better match humanâ€™s expectation.
	vec3 light;
	float intensity;
	#endif
	vec3 diffuse;
	vec3 specular;
	float glossiness;
};

struct Sphere {
	vec3 position;
#ifdef SOLUTION_MB
	vec3 motion;
#endif
	float radius;
	Material material;
};

struct Plane {
	vec3 normal;
	float d;
	Material material;
};

const int sphereCount = 4;
const int planeCount = 4;
const int emittingSphereCount = 2;
#ifdef SOLUTION_BOUNCE
const int maxPathLength = 2;
#else
const int maxPathLength = 1;
#endif 

struct Scene {
	Sphere[sphereCount] spheres;
	Plane[planeCount] planes;
};

struct Ray {
	vec3 origin;
	vec3 direction;
};

// Contains all information pertaining to a ray/object intersection
struct HitInfo {
	bool hit;
	float t;
	vec3 position;
	vec3 normal;
	Material material;
};

// Contains info to sample a direction and this directions probability
struct DirectionSample {
	vec3 direction;
	float probability;
};

HitInfo getEmptyHit() {
	Material emptyMaterial;
	#ifdef SOLUTION_LIGHT
	emptyMaterial.light = vec3(0.0);
	#endif
	emptyMaterial.diffuse = vec3(0.0);
	emptyMaterial.specular = vec3(0.0);
	emptyMaterial.glossiness = 1.0;
	return HitInfo(false, 0.0, vec3(0.0), vec3(0.0), emptyMaterial);
}

// Sorts the two t values such that t1 is smaller than t2
void sortT(inout float t1, inout float t2) {
	// Make t1 the smaller t
	if(t2 < t1)  {
		float temp = t1;
		t1 = t2;
		t2 = temp;
	}
}

// Tests if t is in an interval
bool isTInInterval(const float t, const float tMin, const float tMax) {
	return t > tMin && t < tMax;
}

// Get the smallest t in an interval
bool getSmallestTInInterval(float t0, float t1, const float tMin, const float tMax, inout float smallestTInInterval) {

	sortT(t0, t1);

	// As t0 is smaller, test this first
	if(isTInInterval(t0, tMin, tMax)) {
		smallestTInInterval = t0;
		return true;
	}

	// If t0 was not in the interval, still t1 could be
	if(isTInInterval(t1, tMin, tMax)) {
		smallestTInInterval = t1;
		return true;
	}

	// None was
	return false;
}

// Converts a random integer in 15 bits to a float in (0, 1)
float randomIntegerToRandomFloat(int i) {
	return float(i) / 32768.0;
}

// Returns a random integer for every pixel and dimension that remains the same in all iterations
int pixelIntegerSeed(const int dimensionIndex) {
	vec3 p = vec3(gl_FragCoord.xy, dimensionIndex);
	vec3 r = vec3(23.14069263277926, 2.665144142690225,7.358926345 );
	return int(32768.0 * fract(cos(dot(p,r)) * 123456.0));
}

// Returns a random float for every pixel that remains the same in all iterations
float pixelSeed(const int dimensionIndex) {
	return randomIntegerToRandomFloat(pixelIntegerSeed(dimensionIndex));
}

// The global random seed of this iteration
// It will be set to a new random value in each step
uniform int globalSeed;
int randomSeed;
void initRandomSequence() {
	randomSeed = globalSeed + pixelIntegerSeed(0);
}

// Computes integer  x modulo y not available in most WEBGL SL implementations
int mod(const int x, const int y) {
	return int(float(x) - floor(float(x) / float(y)) * float(y));
}

// Returns the next integer in a pseudo-random sequence
int rand() {
	randomSeed = randomSeed * 1103515245 + 12345;
	return mod(randomSeed / 65536, 32768);
}

float uniformRandomImproved(vec2 co){
    float a = 12.9898;
    float b = 78.233;
    float c = 43758.5453;
    float dt= dot(co.xy ,vec2(a,b));
    float sn= mod(dt,3.14);
    return fract(sin(sn) * c);
}

// Returns the next float in this pixels pseudo-random sequence
float uniformRandom() {
	return randomIntegerToRandomFloat(rand());
}

// This is the index of the sample controlled by the framework.
// It increments by one in every call of this shader
uniform int baseSampleIndex;

#ifdef SOLUTION_VR
// Switches to turn on Halton Sequence / Importance Sampling / Next Event Estimation
bool isHalton = true;
bool importanceSampling = false;
bool NEE = false;

// Halton Sequence Implementation
// For randomly chosen points in a certain space, they seem not to be random. This is because when sample number is small, some places may have high intensity while other don't.
// Halton Sequence is invented to generate points in space for numerical methods such as Monte Carlo simulations. Sequences produced by this method has low discrepancy.
// The sequence is produced using a certain prime number. For example, to generate the sequence for 2, we start by dividing the interval (0,1) in 1/2, then 1/4, 1/8, ... 
// If we want to get 6th number (3/8), then use 6 = 2^2 + 1^2 + 0^2 and invert 2(110) after decimal point as 2(0.011), which is 3/8.
// Reference : https://en.wikipedia.org/wiki/Halton_sequence
// Set the max dimension of Halton Sequence as 10
// prime function returns the prime number corresponding to the given index
const int maxDimensionCount = 10;
int prime(const int index) {
	if(index == 0) return 2;
	if(index == 1) return 3;
	if(index == 2) return 5;
	if(index == 3) return 7;
	if(index == 4) return 11;
	if(index == 5) return 13;
	if(index == 6) return 17;
	if(index == 7) return 19;
	if(index == 8) return 23;
	if(index == 9) return 29;
	if(index == 10) return 31;
	if(index == 11) return 37;
	if(index == 12) return 41;
	if(index == 13) return 43;
	if(index == 14) return 47;
	if(index == 15) return 53;
	return 2;
}
// In this coursework, dimensionIndex represents the base prime and we want to get sampleIndex using baseSampleIndex.
// Because Halton sequence is deterministic pixel-wise. So if we do not add an offset(a random number), the rendering result will show a strange pattern.
// Use pixelSeed function to generate a random offset.
float halton(const int sampleIndex, const int dimensionIndex) {
	float f = 1.0;
	float r = 0.0;
	float b = float(prime(mod(dimensionIndex, maxDimensionCount)));
	int bint = prime(mod(dimensionIndex, maxDimensionCount));
	int i = sampleIndex;
	const int t = 10000;
	for (int j = 0; j < t; j++) {
		// The loop should stop at the first dimension
		if (i == 0) {
			break;
		}
		f /= b;
		r += f * float(mod(i, bint));
		i = i / bint;
	}
	return fract(r + pixelSeed(dimensionIndex));
}
#endif

// Returns a well-distributed number in (0,1) for the dimension dimensionIndex
float sample(const int dimensionIndex) {
	// combining 2 PRNGs to avoid the patterns in the C-standard LCG
	#ifdef SOLUTION_VR
	if (isHalton) return halton(baseSampleIndex, dimensionIndex);
	#endif
	return uniformRandomImproved(vec2(uniformRandom(), uniformRandom()));
}

// This is a helper function to sample two-dimensionaly in dimension dimensionIndex
vec2 sample2(const int dimensionIndex) {
	return vec2(sample(dimensionIndex + 0), sample(dimensionIndex + 1));
}

vec3 sample3(const int dimensionIndex) {
	return vec3(sample(dimensionIndex + 0), sample(dimensionIndex + 1), sample(dimensionIndex + 2));
}

// This is a register of all dimensions that we will want to sample.
// Thanks to Iliyan Georgiev from Solid Angle for explaining proper housekeeping of sample dimensions in ranomdized Quasi-Monte Carlo
//
// There are infinitely many path sampling dimensions.
// These start at PATH_SAMPLE_DIMENSION.
// The 2D sample pair for vertex i is at PATH_SAMPLE_DIMENSION + PATH_SAMPLE_DIMENSION_MULTIPLIER * i + 0
#define ANTI_ALIAS_SAMPLE_DIMENSION 0
#define TIME_SAMPLE_DIMENSION 1
#define PATH_SAMPLE_DIMENSION 3

// This is 2 for two dimensions and 2 as we use it for two purposese: NEE and path connection
#define PATH_SAMPLE_DIMENSION_MULTIPLIER (2 * 2)

vec3 getEmission(const Material material, const vec3 normal) {
	#ifdef SOLUTION_LIGHT
	return material.light * material.intensity;
	#else
	// This is wrong. It just returns the diffuse color so that you see something to be sure it is working.
	return material.diffuse;
	#endif
}

vec3 getReflectance(const Material material, const vec3 normal, const vec3 inDirection, const vec3 outDirection) {
	#ifdef SOLUTION_THROUGHPUT
	// getReflectance function is to compute the BRDF part, which is the fr(x, wi, wo) in the equation.
	// In the equation, kd is diffuse param, ks is specular param, n is glossiness param, vector r is the reflected ray direction
	// First compute the reflected direction using equation : r = e + 2 * <-e, n> * n, and compute the max number between cosin and zero
	// Then multiply other parts using the equation : kd / pi + ks * (n + 2) / (2 * pi) * (<wo, r>+)^n
	float n = material.glossiness;
	vec3 reflectDirection = normalize(reflect(inDirection, normal));
	float cosin = max(0.0, dot(reflectDirection, outDirection));
	vec3 fr = material.diffuse / M_PI + material.specular * (n + 2.0) / (2.0 * M_PI) * pow(cosin, n);
	return fr;
	#else
	return vec3(1.0);
	#endif
}

vec3 getGeometricTerm(const Material material, const vec3 normal, const vec3 inDirection, const vec3 outDirection) {
	#ifdef SOLUTION_THROUGHPUT
	// getGeometricTerm function is to compute the geometric term in the equation, Which is the cos(theta) part.
	// Compute the cosin using dot product as dot(a, b) = |a| * |b| * cosin(a, b).
	return vec3(clamp(dot(normal, outDirection),0.0,1.0));
	#else
	return vec3(1.0);
	#endif
}

vec3 sphericalToEuclidean(float theta, float phi) {
	float x = sin(theta) * cos(phi);
	float y = sin(theta) * sin(phi);
	float z = cos(theta);
	return vec3(x, y, z);	
}

vec3 getRandomDirection(const int dimensionIndex) {
	#ifdef SOLUTION_BOUNCE
	// There are 2 logical parts.
	// The first part is to generate 2 ramdom numbers. We can call sample function twice or call sample2 function.
	// The second parts is to generate spherical coords using the 2 random nubmers and then calculate Euclidea coords.
	// float e0 = sample(dimensionIndex);
	// float e1 = sample(dimensionIndex);
	vec2 e = sample2(dimensionIndex);
	float e0 = e[0];
	float e1 = e[1];
	float theta = acos(2.0 * e0 - 1.0);
	float phi = e1 * 2.0 * M_PI;
	vec3 coords = sphericalToEuclidean(theta, phi);

	return coords;
	
	#else
	// Put your code to compute a random direction in 3D in the #ifdef above
	return vec3(0);
	#endif
}


HitInfo intersectSphere(const Ray ray, Sphere sphere, const float tMin, const float tMax) {

#ifdef SOLUTION_MB
	// Set speed as 1 / totalTime, where totalTime is the max step user set on this website.
	// Use the uniform variable baseSampleIndex as it can automatically increase every step.
	float speed = 0.001;
	sphere.position += sphere.motion * speed * float(baseSampleIndex);
#endif
	vec3 to_sphere = ray.origin - sphere.position;

	float a = dot(ray.direction, ray.direction);
	float b = 2.0 * dot(ray.direction, to_sphere);
	float c = dot(to_sphere, to_sphere) - sphere.radius * sphere.radius;
	float D = b * b - 4.0 * a * c;
	if (D > 0.0)
	{
		float t0 = (-b - sqrt(D)) / (2.0 * a);
		float t1 = (-b + sqrt(D)) / (2.0 * a);

		float smallestTInInterval;
		if(!getSmallestTInInterval(t0, t1, tMin, tMax, smallestTInInterval)) {
			return getEmptyHit();
		}

		vec3 hitPosition = ray.origin + smallestTInInterval * ray.direction;

		vec3 normal =
			length(ray.origin - sphere.position) < sphere.radius + 0.001?
			-normalize(hitPosition - sphere.position) :
		normalize(hitPosition - sphere.position);

		return HitInfo(
			true,
			smallestTInInterval,
			hitPosition,
			normal,
			sphere.material);
	}
	return getEmptyHit();
}

HitInfo intersectPlane(Ray ray, Plane plane) {
	float t = -(dot(ray.origin, plane.normal) + plane.d) / dot(ray.direction, plane.normal);
	vec3 hitPosition = ray.origin + t * ray.direction;
	return HitInfo(
		true,
		t,
		hitPosition,
		normalize(plane.normal),
		plane.material);
	return getEmptyHit();
}

float lengthSquared(const vec3 x) {
	return dot(x, x);
}

HitInfo intersectScene(Scene scene, Ray ray, const float tMin, const float tMax)
{
	HitInfo best_hit_info;
	best_hit_info.t = tMax;
	best_hit_info.hit = false;

	for (int i = 0; i < sphereCount; ++i) {
		Sphere sphere = scene.spheres[i];
		HitInfo hit_info = intersectSphere(ray, sphere, tMin, tMax);

		if(	hit_info.hit &&
		   hit_info.t < best_hit_info.t &&
		   hit_info.t > tMin)
		{
			best_hit_info = hit_info;
		}
	}

	for (int i = 0; i < planeCount; ++i) {
		Plane plane = scene.planes[i];
		HitInfo hit_info = intersectPlane(ray, plane);

		if(	hit_info.hit &&
		   hit_info.t < best_hit_info.t &&
		   hit_info.t > tMin)
		{
			best_hit_info = hit_info;
		}
	}

	return best_hit_info;
}

mat3 transpose(mat3 m) {
	return mat3(
		m[0][0], m[1][0], m[2][0],
		m[0][1], m[1][1], m[2][1],
		m[0][2], m[1][2], m[2][2]
	);
}

// This function creates a matrix to transform from global space into a local space oriented around the provided vector.
// The strategy of making a local axis is to set a fixed vector like (0, 0, 1), and use corss product between the fixed vector and normal vector to get a new vector on the plane that is perpendicular to the normal vector. Then also use corss product between the new axis and normal vector to get the third axis.
// There is a little bug that when the fixed seed vector is the same as given normal vector, the new axis will be (0, 0, 0,). Solution is to avoid this situation by return a fixed correct local axis like (1, 1, 1).
mat3 makeLocalFrame(const vec3 vector) {
	#ifdef SOLUTION_VR
	vec3 up = vec3(0, 0, 1);
	if (all(lessThan(abs(vector - up), vec3(0.001)))) return mat3(1.0);
	vec3 axis1 = normalize(cross(vector, up));
	vec3 axis2 = normalize(cross(axis1, vector));
	vec3 axis3 = vector;
	return mat3(axis1, axis2, axis3);
	#else
	return mat3(1.0);
	#endif
}

float luminance(const vec3 color) {
    return dot(color, vec3(0.2126, 0.7152, 0.0722));
}

#define EPSILON (1e-6)  // for avoiding numeric issues caused by floating point accuracy

DirectionSample sampleDirection(const vec3 normal, const vec3 inDirection, const vec3 diffuse, const vec3 specular, const float n, const int dimensionIndex) {
	DirectionSample result;
		
	#ifdef SOLUTION_VR
	if (importanceSampling){
		// Importance Sampling Implementation
		// The strategy of importance sampling is to put more weight on the direction that is more significant for rendering in sampling.
		// 1st: We do not need to sample directions in a sphere space but a semi-sphere space as we do not need to calculate information inside an object.
		// 2nd: For diffuse, we want to sample more directions when they are closed to normal vector because light from around normal is important for diffuse or reflectance.
		// 3nd: For specular, we use acos(e^(1/glossiness)) as phi. When glossiness is larger, e ^ (1/glossiness) will be near 1, then acos() wil be near zero. So phi will be near zero, which means we are more likely to sample points near ideal reflection direction. So we can speed up the process of spcular if glossiness is larger.
		// 4th: Calculate the luminance for diffuse and specular and take normalization of them. Use normalized diffuse luminance as threshold(probability) to judge whether we should speed up diffuse part or specular part. I also set a flag(includeSpecular) to decide whether we should speed up specular process or not.
		float diffuseLuminance = luminance(diffuse);
		float specularLuminance = luminance(specular);
		float totalLuminance = (diffuseLuminance + specularLuminance + EPSILON);
		diffuseLuminance /= totalLuminance;
		specularLuminance /= totalLuminance;
		
		bool includeSpecular = true;
		float randomValue = sample(dimensionIndex);
		float threshold = includeSpecular ? diffuseLuminance : 1.0;
		if (randomValue < threshold) {
			// To sample on a semi-sphere, we need to build a local axis
			// mat3 coord = makeLocalFrame(normal);
			// Almost the same but the range for theta is not (-1, 1) but (0, 1), so we can sample on a semi-sphere
			vec2 e = sample2(dimensionIndex);
			float theta = acos(sqrt(e.x));
			float phi = e.y * 2.0 * M_PI;
			vec3 sampleDir = sphericalToEuclidean(theta, phi);
			// Transfer coords from original axis to local axis, can imagine coord[0~2] to be x,y,z axis.
			mat3 localCoord = makeLocalFrame(normal);
			// Importance step for Importance Sampling, we want to put more probability when the random direction is closed to normal vector.
			vec3 randomDirection = localCoord * sampleDir;
			result.direction = randomDirection;
			// sampleDir.z means cosin between cosin between randomDirection and normal. If z value is larger, then we are sampling direction closer to normal.
			result.probability = sampleDir.z / M_PI;
			
		} else {
			// Almost the same compared with diffuse case. The calculation of theta and probability is different.
			vec2 e = sample2(dimensionIndex);https://uclcg.github.io/uclcg/public/html/index.html#
			float theta = acos(pow(1.0 - e.x, 1.0 / (n + 1.0)));
			float phi = e.y * 2.0 * M_PI;
			vec3 sampleDir = sphericalToEuclidean(theta, phi);
			
			vec3 reflectDirection = reflect(inDirection, normal);
			mat3 localCoord = makeLocalFrame(reflectDirection);
			
			vec3 randomDirection = localCoord * sampleDir;
			result.direction = localCoord * sampleDir;
			result.probability = (n + 1.0) / (2.0 * M_PI) * pow(sampleDir.z, n);
			
		}
	} else {
		result.direction = getRandomDirection(dimensionIndex);	
		result.probability = 1.0 / (4.0 * M_PI);
	}

	
	#else
	// Depending on the technique: put your variance reduction code in the #ifdef above 
	result.direction = getRandomDirection(dimensionIndex);	
	result.probability = 1.0 / (4.0 * M_PI);
	#endif
	return result;
}

vec3 samplePath(const Scene scene, const Ray initialRay) {

	// Initial result is black
	vec3 result = vec3(0);

	Ray incomingRay = initialRay;
	vec3 throughput = vec3(1.0);
	for(int i = 0; i < maxPathLength; i++) {
		HitInfo hitInfo = intersectScene(scene, incomingRay, 0.001, 10000.0);
		if(!hitInfo.hit) return result;
		 	
		#ifdef SOLUTION_VR
		// Implementation of Next Event Estimation method
		// 1st: For each bounce, we want to combine direct light and indriect light. It would be slow for original method as random direction may hardly hit light source.
		// 2nd: For each bounce, create a new ray towards every light source and calculate whether there are obstacles. If there are no obstacles, we can calculate direct light and add to final result.
		// 3rd: When calculating direct light, we pick a random point on the sphere light source. Then calculate the intersection point on the sphere between light sample point and current hit point, and update the light sample. The reason to do so is to avoid error when judging whether there is an obstacle afterwards.
		if(NEE){
			vec3 directLighting = vec3(0.0);
			// Loop every sphere light source
			for (int j = 0; j < emittingSphereCount; ++j){
				Sphere lightSource = scene.spheres[j];
				// Randomly pick a point on the sphere light source
				vec3 lightSample = getRandomDirection(PATH_SAMPLE_DIMENSION_MULTIPLIER * j) * lightSource.radius + lightSource.position;
				// Update light sample, use the closest point that is at the front side of the sphere.
				lightSample = intersectSphere(Ray(hitInfo.position, lightSample - hitInfo.position), lightSource, 0.001, 10000.0).position;
				vec3 toLight = lightSample - hitInfo.position;
				float distanceToLight = length(toLight);
				toLight /= distanceToLight;
				// Create a new ray to detect whether there is an obstacle towards light sample.
				Ray shadowRay;
           shadowRay.origin = hitInfo.position + hitInfo.normal * 0.001;
           shadowRay.direction = toLight;
           HitInfo shadowHit = intersectScene(scene, shadowRay, 0.001, 10000.0);
				// If there is no obstacles, then calculate direct light. Direct light = throughput * BRDF * light / 4pi
				if (!shadowHit.hit || shadowHit.t > distanceToLight) {
					float cosTheta = dot(hitInfo.normal, toLight);
					if (cosTheta > 0.0) {
						vec3 lightIntensity = getEmission(lightSource.material, toLight);
						vec3 reflectance = getReflectance(hitInfo.material, hitInfo.normal, incomingRay.direction, toLight);
						directLighting += throughput * reflectance * lightIntensity * cosTheta / (4.0 * M_PI);
					}
				}
			}
			// At last, combine direct light and indriect ligth.
			result += directLighting + throughput * getEmission(hitInfo.material, hitInfo.normal);
		}
		#else
			result += throughput * getEmission(hitInfo.material, hitInfo.normal);
		#endif
		Ray outgoingRay;
		DirectionSample directionSample;
		#ifdef SOLUTION_BOUNCE
		directionSample = sampleDirection(hitInfo.normal, incomingRay.direction, hitInfo.material.diffuse, hitInfo.material.specular, hitInfo.material.glossiness, PATH_SAMPLE_DIMENSION + 2 * i);
		outgoingRay.origin = hitInfo.position;
		outgoingRay.direction = directionSample.direction;
		#else
			// Put your code to compute the next ray in the #ifdef above
		#endif
		
		#ifdef UNIT_TEST
		// Test whether sampleDirection returns a direction that is randomly distributed on a sphere.
		// Can only test whether the length of direction is closed to 1.0. If the length is bigger or lesser over a threshold, this function will return a white point.
		// If set threshold to 0.00001 or lesser, you will see a lot of white points on the frame. But 0.00001 is small enough to prove sampleDirection is on a sphere.
		float threshold = 0.001;
		if (abs(length(directionSample.direction) - 1.0) > threshold) return vec3(1.0);
		else return vec3(0.0);
		#endif

		#ifdef SOLUTION_THROUGHPUT
		// Implementations of getReflectance and getGeometricTerm by multiplying the returning results to throughput. Instead of multiplying 0.1
		vec3 geometryTerm = getGeometricTerm(hitInfo.material, hitInfo.normal, incomingRay.direction, outgoingRay.direction);
		vec3 reflectance = getReflectance(hitInfo.material, hitInfo.normal, incomingRay.direction, outgoingRay.direction);
		
		throughput *= geometryTerm * reflectance;
		#else
		// Compute the proper throughput in the #ifdef above 
		throughput *= 0.1;
		#endif

		// div by probability of sampled direction 
		throughput /= directionSample.probability; 
	
		#ifdef SOLUTION_BOUNCE
		incomingRay.direction = outgoingRay.direction;
		incomingRay.origin = hitInfo.position;
		#else
		// Put some handling of the next and the current ray in the #ifdef above
		#endif
	}
	return result;
}

uniform ivec2 resolution;
Ray getFragCoordRay(const vec2 fragCoord) {

	float sensorDistance = 1.0;
	vec3 origin = vec3(0, 0, sensorDistance);
	vec2 sensorMin = vec2(-1, -0.5);
	vec2 sensorMax = vec2(1, 0.5);
	vec2 pixelSize = (sensorMax - sensorMin) / vec2(resolution);
	vec3 direction = normalize(vec3(sensorMin + pixelSize * fragCoord, -sensorDistance));

	float apertureSize = 0.0;
	float focalPlane = 100.0;
	vec3 sensorPosition = origin + focalPlane * direction;
	origin.xy += -vec2(0.5);
	direction = normalize(sensorPosition - origin);

	return Ray(origin, direction);
}

vec3 colorForFragment(const Scene scene, const vec2 fragCoord) {
	initRandomSequence();

	#ifdef SOLUTION_AA
	// To add anti-asliasing, we need to add a random offset to fragCoord so that we can render a pixel using a slightly surrounding ray.
	// In this case, sharp edges can be blurred because we are not rendering the exact edge but a surrounding position.
	// In a low resolution, edges is jagged as curves can not be presented correctly. So we need to capture information near edges.
	float window = 0.5;
	vec2 randomOffset = window * (2.0 * vec2(uniformRandom(), uniformRandom()) - 1.0 );
	vec2 sampleCoord = fragCoord + randomOffset;
	#else  	
	// Put your anti-aliasing code in the #ifdef above
	vec2 sampleCoord = fragCoord;
	#endif
	return samplePath(scene, getFragCoordRay(sampleCoord));
}

void loadScene1(inout Scene scene) {

	scene.spheres[0].position = vec3(7, -2, -12);
	scene.spheres[0].radius = 2.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[0].material.light = vec3(0.9, 0.9, 0.5);
	scene.spheres[0].material.intensity = 15.0;
#endif
	scene.spheres[0].material.diffuse = vec3(0.5);
	scene.spheres[0].material.specular = vec3(0.5);
	scene.spheres[0].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[0].motion = vec3(0.0);
#endif
	
	scene.spheres[1].position = vec3(-8, 4, -13);
	scene.spheres[1].radius = 1.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[1].material.light = vec3(0.8, 0.3, 0.1);
	scene.spheres[1].material.intensity = 15.0;
#endif
	scene.spheres[1].material.diffuse = vec3(0.5);
	scene.spheres[1].material.specular = vec3(0.5);
	scene.spheres[1].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[1].motion = vec3(0.0);
#endif
	
	scene.spheres[2].position = vec3(-2, -2, -12);
	scene.spheres[2].radius = 3.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[2].material.light = vec3(0.0);
	scene.spheres[2].material.intensity = 0.0;
#endif  
	scene.spheres[2].material.diffuse = vec3(0.2, 0.5, 0.8);
	scene.spheres[2].material.specular = vec3(0.8);
	scene.spheres[2].material.glossiness = 40.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[2].motion = vec3(-3.0, 0.0, 3.0);
#endif
	
	scene.spheres[3].position = vec3(3, -3.5, -14);
	scene.spheres[3].radius = 1.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[3].material.light = vec3(0.0);
	scene.spheres[3].material.intensity = 0.0;
#endif  
	scene.spheres[3].material.diffuse = vec3(0.9, 0.8, 0.8);
	scene.spheres[3].material.specular = vec3(1.0);
	scene.spheres[3].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[3].motion = vec3(2.0, 4.0, 1.0);
#endif
	
	scene.planes[0].normal = vec3(0, 1, 0);
	scene.planes[0].d = 4.5;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[0].material.light = vec3(0.0);
	scene.planes[0].material.intensity = 0.0;
#endif
	scene.planes[0].material.diffuse = vec3(0.8);
	scene.planes[0].material.specular = vec3(0.0);
	scene.planes[0].material.glossiness = 50.0;    

	scene.planes[1].normal = vec3(0, 0, 1);
	scene.planes[1].d = 18.5;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.planes[1].material.light = vec3(0.0);
	scene.planes[1].material.intensity = 0.0;
#endif
	scene.planes[1].material.diffuse = vec3(0.9, 0.6, 0.3);
	scene.planes[1].material.specular = vec3(0.02);
	scene.planes[1].material.glossiness = 3000.0;

	scene.planes[2].normal = vec3(1, 0,0);
	scene.planes[2].d = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[2].material.light = vec3(0.0);
	scene.planes[2].material.intensity = 0.0;
#endif
	
	scene.planes[2].material.diffuse = vec3(0.2);
	scene.planes[2].material.specular = vec3(0.1);
	scene.planes[2].material.glossiness = 100.0; 

	scene.planes[3].normal = vec3(-1, 0,0);
	scene.planes[3].d = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[3].material.light = vec3(0.0);
	scene.planes[3].material.intensity = 0.0;
#endif
	
	scene.planes[3].material.diffuse = vec3(0.2);
	scene.planes[3].material.specular = vec3(0.1);
	scene.planes[3].material.glossiness = 100.0; 
}


void main() {
	// Setup scene
	Scene scene;
	loadScene1(scene);

	// compute color for fragment
	gl_FragColor.rgb = colorForFragment(scene, gl_FragCoord.xy);
	gl_FragColor.a = 1.0;
}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	UI.tabs.push(
		{
		visible: true,
		type: `x-shader/x-fragment`,
		title: `Tonemapping`,
		id: `CopyFS`,
		initialValue: `precision highp float;

uniform sampler2D radianceTexture;
uniform int sampleCount;
uniform ivec2 resolution;

vec3 tonemap(vec3 color, float maxLuminance, float gamma) {
	float luminance = length(color);
	//float scale =  luminance /  maxLuminance;
	float scale =  luminance / (maxLuminance * luminance + 0.0000001);
  	return max(vec3(0.0), pow(scale * color, vec3(1.0 / gamma)));
}

void main(void) {
  vec3 texel = texture2D(radianceTexture, gl_FragCoord.xy / vec2(resolution)).rgb;
  vec3 radiance = texel / float(sampleCount);
  gl_FragColor.rgb = tonemap(radiance, 1.0, 1.6);
  gl_FragColor.a = 1.0;
}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	UI.tabs.push(
		{
		visible: false,
		type: `x-shader/x-vertex`,
		title: ``,
		id: `VS`,
		initialValue: `
	attribute vec3 position;
	void main(void) {
		gl_Position = vec4(position, 1.0);
	}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	 return UI; 
}//!setup


function getShader(gl, id) {

		gl.getExtension('OES_texture_float');
		//alert(gl.getSupportedExtensions());

	var shaderScript = document.getElementById(id);
	if (!shaderScript) {
		return null;
	}

	var str = "";
	var k = shaderScript.firstChild;
	while (k) {
		if (k.nodeType == 3) {
			str += k.textContent;
		}
		k = k.nextSibling;
	}

	var shader;
	if (shaderScript.type == "x-shader/x-fragment") {
		shader = gl.createShader(gl.FRAGMENT_SHADER);
	} else if (shaderScript.type == "x-shader/x-vertex") {
		shader = gl.createShader(gl.VERTEX_SHADER);
	} else {
		return null;
	}

    console.log(str);
	gl.shaderSource(shader, str);
	gl.compileShader(shader);

	if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
		alert(gl.getShaderInfoLog(shader));
		return null;
	}

	return shader;
}

function RaytracingDemo() {
}

function initShaders() {

	traceProgram = gl.createProgram();
	gl.attachShader(traceProgram, getShader(gl, "VS"));
	gl.attachShader(traceProgram, getShader(gl, "TraceFS"));
	gl.linkProgram(traceProgram);
	gl.useProgram(traceProgram);
	traceProgram.vertexPositionAttribute = gl.getAttribLocation(traceProgram, "position");
	gl.enableVertexAttribArray(traceProgram.vertexPositionAttribute);

	copyProgram = gl.createProgram();
	gl.attachShader(copyProgram, getShader(gl, "VS"));
	gl.attachShader(copyProgram, getShader(gl, "CopyFS"));
	gl.linkProgram(copyProgram);
	gl.useProgram(copyProgram);
	traceProgram.vertexPositionAttribute = gl.getAttribLocation(copyProgram, "position");
	gl.enableVertexAttribArray(copyProgram.vertexPositionAttribute);

}

function initBuffers() {
	triangleVertexPositionBuffer = gl.createBuffer();
	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);

	var vertices = [
		 -1,  -1,  0,
		 -1,  1,  0,
		 1,  1,  0,

		 -1,  -1,  0,
		 1,  -1,  0,
		 1,  1,  0,
	 ];
	gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW);
	triangleVertexPositionBuffer.itemSize = 3;
	triangleVertexPositionBuffer.numItems = 3 * 2;
}


function tick() {

// 1st pass: Trace
	gl.bindFramebuffer(gl.FRAMEBUFFER, rttFramebuffer);

	gl.useProgram(traceProgram);
  	gl.uniform1i(gl.getUniformLocation(traceProgram, "globalSeed"), Math.random() * 32768.0);
	gl.uniform1i(gl.getUniformLocation(traceProgram, "baseSampleIndex"), getCurrentFrame());
	gl.uniform2i(
		gl.getUniformLocation(traceProgram, "resolution"),
		getRenderTargetWidth(),
		getRenderTargetHeight());

	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);
	gl.vertexAttribPointer(
		traceProgram.vertexPositionAttribute,
		triangleVertexPositionBuffer.itemSize,
		gl.FLOAT,
		false,
		0,
		0);

    	gl.viewport(0, 0, gl.viewportWidth, gl.viewportHeight);

	gl.disable(gl.DEPTH_TEST);
	gl.enable(gl.BLEND);
	gl.blendFunc(gl.ONE, gl.ONE);

	gl.drawArrays(gl.TRIANGLES, 0, triangleVertexPositionBuffer.numItems);

// 2nd pass: Average
   	gl.bindFramebuffer(gl.FRAMEBUFFER, null);

	gl.useProgram(copyProgram);
	gl.uniform1i(gl.getUniformLocation(copyProgram, "sampleCount"), getCurrentFrame() + 1);

	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);
	gl.vertexAttribPointer(
		copyProgram.vertexPositionAttribute,
		triangleVertexPositionBuffer.itemSize,
		gl.FLOAT,
		false,
		0,
		0);

    	gl.viewport(0, 0, gl.viewportWidth, gl.viewportHeight);

	gl.disable(gl.DEPTH_TEST);
	gl.disable(gl.BLEND);

	gl.activeTexture(gl.TEXTURE0);
    	gl.bindTexture(gl.TEXTURE_2D, rttTexture);
	gl.uniform1i(gl.getUniformLocation(copyProgram, "radianceTexture"), 0);
	gl.uniform2i(
		gl.getUniformLocation(copyProgram, "resolution"),
		getRenderTargetWidth(),
		getRenderTargetHeight());

	gl.drawArrays(gl.TRIANGLES, 0, triangleVertexPositionBuffer.numItems);

	gl.bindTexture(gl.TEXTURE_2D, null);
}

function init() {
	initShaders();
	initBuffers();
	gl.clear(gl.COLOR_BUFFER_BIT);

	rttFramebuffer = gl.createFramebuffer();
	gl.bindFramebuffer(gl.FRAMEBUFFER, rttFramebuffer);

	rttTexture = gl.createTexture();
	gl.bindTexture(gl.TEXTURE_2D, rttTexture);
    	gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
    	gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);

	gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, getRenderTargetWidth(), getRenderTargetHeight(), 0, gl.RGBA, gl.FLOAT, null);

	gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, rttTexture, 0);
}

var oldWidth = 0;
var oldTraceProgram;
var oldCopyProgram;
function compute(canvas) {

	if(	getRenderTargetWidth() != oldWidth ||
		oldTraceProgram != document.getElementById("TraceFS") ||
		oldCopyProgram !=  document.getElementById("CopyFS"))
	{
		init();

		oldWidth = getRenderTargetWidth();
		oldTraceProgram = document.getElementById("TraceFS");
		oldCopyProgram = document.getElementById("CopyFS");
	}

	tick();
}
